name: Monthly Scraping Job

# Controls when the action will run, which is on the first day of every month at midnight (00:00) Switzerland time
on:
  schedule:
    - cron: '0 22 5 * *'  # This represents 22:00 UTC on the 2nd day of every month (which is 00:00 in Switzerland)
    - cron: '0 22 25 * *'

jobs:
  scraping_and_processing:
    runs-on: ubuntu-latest

    steps:
      # Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Set the Zurich timezone (Switzerland)
      - name: Set timezone
        run: sudo timedatectl set-timezone Europe/Zurich

      # Install Python env
      - name: Set up Python 3.11.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.11.8'

      # Install Python dependencies
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          cd src/scraping/ScrapingWithPDF
          pip install -r requirements.txt

      # Step 1: Run the first script (scraping metadata)
      - name: Run metadata scraping script
        env:
          ATLAS_USER: ${{ secrets.ATLAS_USER }}
          ATLAS_TOKEN: ${{ secrets.ATLAS_TOKEN }}
        run: |
          cd src/scraping/ScrapingWithPDF
          python 1_scrapingMetadata.py

      # Step 2: Run the second script (processing and embedding)
      - name: Run feedback processing script
        env:
          ATLAS_USER: ${{ secrets.ATLAS_USER }}
          ATLAS_TOKEN: ${{ secrets.ATLAS_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          cd src/scraping/ScrapingWithPDF
          python 2_preprocessingMetadata.py

      # Step 3: Run the third script (visualization)
      - name: Run initiative info script
        env:
          ATLAS_USER: ${{ secrets.ATLAS_USER }}
          ATLAS_TOKEN: ${{ secrets.ATLAS_TOKEN }}
        run: |
          cd src/scraping/ScrapingWithPDF
          python 3_dataVisualization.py